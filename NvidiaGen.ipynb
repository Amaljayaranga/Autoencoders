{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NvidiaGen.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmeiM+Tiajuk4cjwFeVP1E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amaljayaranga/Autoencoders/blob/master/NvidiaGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI6Pfn2asuxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0cd2d7ff-bed6-47c0-8a9d-1fcdb6ce5fb4"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from argparse import ArgumentParser\n",
        "import seaborn as sns;sns.set()\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "Z_SIZE = 1024\n",
        "IN_Channels = int(Z_SIZE/16)\n",
        "\n",
        "\n",
        "parser = ArgumentParser(description='Simase Network')\n",
        "parser.add_argument('--learning_batch_size', type=int, default=64)\n",
        "parser.add_argument('--fc_in_features', type=int, default=512)\n",
        "parser.add_argument('--fc_out_features', type=int, default=64)\n",
        "parser.add_argument('--constractive_loss_margin', type=float, default=1.0)\n",
        "parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
        "parser.add_argument('--num_epochs', type=int, default=100)\n",
        "parser.add_argument('--weight_decay', type=float, default=1e-5)\n",
        "parser.add_argument('--validation_split', type=float, default=0.2)\n",
        "parser.add_argument('--mode', type=str, default='train')\n",
        "parser.add_argument('--device', type=str, default='cuda')\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "\n",
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self, epsilon=1e-8):\n",
        "        super(PixelNorm, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, x):\n",
        "        tmp = torch.mul(x, x)\n",
        "        tmp = torch.rsqrt(torch.mean(tmp, dim=1, keepdim=True) + self.epsilon)\n",
        "        return x * tmp\n",
        "\n",
        "class Reshape(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Reshape, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,IN_Channels,4,4)\n",
        "        return x\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "\n",
        "    def __init__(self,in_channel, out_channel):\n",
        "        super(ConvBlock,self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "                                    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                    nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1),\n",
        "                                    nn.LeakyReLU(),\n",
        "                                    PixelNorm(),\n",
        "                                    nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1),\n",
        "                                    nn.LeakyReLU(),\n",
        "                                    PixelNorm(),\n",
        "                                    )\n",
        "    def forward(self, x):\n",
        "         x = self.conv(x)\n",
        "         return x\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Encoder,self).__init__()\n",
        "\n",
        "        encoder_pretrained = torchvision.models.densenet121(pretrained=True)\n",
        "        features_pretrained = next(iter(encoder_pretrained.children()))\n",
        "\n",
        "        self.encoder = torch.nn.Sequential()\n",
        "        self.z_num_features = 0\n",
        "        for name, module in features_pretrained.named_children():\n",
        "            if name == 'norm5':\n",
        "                self.z_num_features = module.num_features\n",
        "            self.encoder.add_module(name, module)\n",
        "        self.encoder.add_module('avg_pool', torch.nn.AdaptiveAvgPool2d(output_size=1))\n",
        "        #z size = 1024\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return z\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.initial = nn.Sequential(PixelNorm(),\n",
        "                                     nn.Linear(Z_SIZE, Z_SIZE),\n",
        "                                     nn.LeakyReLU(),\n",
        "                                     PixelNorm(),\n",
        "                                     Reshape(),\n",
        "                                     nn.Conv2d(in_channels=IN_Channels, out_channels=IN_Channels, kernel_size=3, stride=1, padding=1),\n",
        "                                     nn.LeakyReLU(),\n",
        "                                     PixelNorm()\n",
        "                                     )\n",
        "\n",
        "        self.middle = nn.Sequential(ConvBlock(IN_Channels,IN_Channels), #8\n",
        "                                    ConvBlock(IN_Channels,IN_Channels), #16\n",
        "                                    ConvBlock(IN_Channels,IN_Channels), #32\n",
        "                                    ConvBlock(IN_Channels,IN_Channels), #64\n",
        "                                    ConvBlock(IN_Channels,IN_Channels), #128\n",
        "                                    ConvBlock(IN_Channels,IN_Channels), #256\n",
        "                                    ConvBlock(IN_Channels,IN_Channels), #512\n",
        "                                    ConvBlock(IN_Channels, IN_Channels)) #1024\n",
        "\n",
        "        self.last = nn.Conv2d(in_channels=IN_Channels, out_channels=3, kernel_size=1)\n",
        "\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.initial(z)\n",
        "        x = self.middle(x)\n",
        "        x = self.last(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Full(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Full, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder()\n",
        "        self.genarator = Generator()\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        z = z.view(-1, Z_SIZE)\n",
        "        out = self.genarator(z)\n",
        "        return out\n",
        "\n",
        "\n",
        "def draw(features):\n",
        "    features1 = features.squeeze()\n",
        "    to_pil = torchvision.transforms.ToPILImage()\n",
        "    img = to_pil(features1)\n",
        "    img.show()\n",
        "\n",
        "def display_image(img):\n",
        "  img1 = img.squeeze()\n",
        "  img1 = img1.detach().numpy()\n",
        "  img1 = np.reshape(img1, (1024, 1024,3))\n",
        "  print(img1)\n",
        "  img2 = (img1 * 255).astype(np.uint8)\n",
        "  print(img2)\n",
        "  plt.figure()\n",
        "  plt.imshow(img2)\n",
        "  #plt.imshow((img1 * 255).astype(np.uint8))\n",
        "  plt.grid(False);  plt.axis('off'); plt.show()\n",
        "\n",
        "\n",
        "# Datasets from folders\n",
        "data = {\n",
        "    'train':\n",
        "    datasets.ImageFolder(root='./train/',\n",
        "                         transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])),\n",
        "    'valid':\n",
        "    datasets.ImageFolder(root='./test/', \n",
        "                         transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])),\n",
        "}\n",
        "\n",
        "# Dataloader iterators, make sure to shuffle\n",
        "dataloaders = {\n",
        "    'train': DataLoader(data['train'], batch_size=1, shuffle=True),\n",
        "    'valid': DataLoader(data['valid'], batch_size=1, shuffle=True)\n",
        "}\n",
        "\n",
        "DEVICE = args.device\n",
        "if not torch.cuda.is_available():\n",
        "    DEVICE = 'cpu'\n",
        "\n",
        "\n",
        "model = Full()\n",
        "model = model.to(DEVICE)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
        "\n",
        "train = False\n",
        "\n",
        "if train:\n",
        "    for epoch in range(args.num_epochs):\n",
        "        for image, label in iter(dataloaders['train']):\n",
        "            image = image.to(DEVICE)\n",
        "            output = model(image)\n",
        "            loss = criterion(output,image)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print('Epoch :', epoch+1, 'Loss:',loss.item())\n",
        "\n",
        "    torch.save(model, './nn_autoencoder.pth')\n",
        "\n",
        "if not train:\n",
        "    model = torch.load('./nn_autoencoder.pth')\n",
        "    model = model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    for image, label in iter(dataloaders['valid']):\n",
        "        image = image.to(DEVICE)\n",
        "        output = model(image)\n",
        "        output = output.to('cpu')\n",
        "        print(output.shape)\n",
        "        display_image(output)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 1024, 1024])\n",
            "[[[ 0.21184894  0.20294556  0.20350733]\n",
            "  [ 0.20321906  0.20338091  0.20332867]\n",
            "  [ 0.20320848  0.20320189  0.20317945]\n",
            "  ...\n",
            "  [ 0.23099533  0.23099098  0.2309798 ]\n",
            "  [ 0.23095223  0.23099083  0.23084071]\n",
            "  [ 0.23132166  0.23481604  0.24651265]]\n",
            "\n",
            " [[ 0.21384671  0.23335677  0.23166817]\n",
            "  [ 0.23097762  0.23067984  0.23064357]\n",
            "  [ 0.23062661  0.23066011  0.23067105]\n",
            "  ...\n",
            "  [ 0.23029274  0.23028797  0.23027763]\n",
            "  [ 0.23028588  0.23029798  0.23013201]\n",
            "  [ 0.2305375   0.23328951  0.24537647]]\n",
            "\n",
            " [[ 0.2127808   0.23291495  0.23149738]\n",
            "  [ 0.23070869  0.23030296  0.23031062]\n",
            "  [ 0.23033059  0.23035115  0.23035887]\n",
            "  ...\n",
            "  [ 0.230326    0.23032779  0.23031473]\n",
            "  [ 0.23032299  0.2303178   0.23011184]\n",
            "  [ 0.23055151  0.23344952  0.24546796]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.08627176 -0.11476299 -0.11411984]\n",
            "  [-0.11397111 -0.11408366 -0.11400025]\n",
            "  [-0.11401201 -0.11404458 -0.11403187]\n",
            "  ...\n",
            "  [-0.11401748 -0.1140267  -0.11400975]\n",
            "  [-0.11405409 -0.11399643 -0.11393639]\n",
            "  [-0.11423164 -0.11653529 -0.11650985]]\n",
            "\n",
            " [[-0.08617805 -0.11474046 -0.11414021]\n",
            "  [-0.11400952 -0.11408791 -0.11401088]\n",
            "  [-0.11403514 -0.11406639 -0.11405006]\n",
            "  ...\n",
            "  [-0.11387598 -0.11389764 -0.11388725]\n",
            "  [-0.11394294 -0.11385617 -0.11396115]\n",
            "  [-0.114071   -0.11635539 -0.11635266]]\n",
            "\n",
            " [[-0.08720446 -0.11489765 -0.11383168]\n",
            "  [-0.11301091 -0.11344717 -0.11339225]\n",
            "  [-0.11335837 -0.11338484 -0.11334728]\n",
            "  ...\n",
            "  [-0.11571869 -0.11573096 -0.11576745]\n",
            "  [-0.11577167 -0.11555701 -0.11616165]\n",
            "  [-0.11712006 -0.12098807 -0.15187365]]]\n",
            "[[[ 54  51  51]\n",
            "  [ 51  51  51]\n",
            "  [ 51  51  51]\n",
            "  ...\n",
            "  [ 58  58  58]\n",
            "  [ 58  58  58]\n",
            "  [ 58  59  62]]\n",
            "\n",
            " [[ 54  59  59]\n",
            "  [ 58  58  58]\n",
            "  [ 58  58  58]\n",
            "  ...\n",
            "  [ 58  58  58]\n",
            "  [ 58  58  58]\n",
            "  [ 58  59  62]]\n",
            "\n",
            " [[ 54  59  59]\n",
            "  [ 58  58  58]\n",
            "  [ 58  58  58]\n",
            "  ...\n",
            "  [ 58  58  58]\n",
            "  [ 58  58  58]\n",
            "  [ 58  59  62]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[235 227 227]\n",
            "  [227 227 227]\n",
            "  [227 227 227]\n",
            "  ...\n",
            "  [227 227 227]\n",
            "  [227 227 227]\n",
            "  [227 227 227]]\n",
            "\n",
            " [[235 227 227]\n",
            "  [227 227 227]\n",
            "  [227 227 227]\n",
            "  ...\n",
            "  [227 227 227]\n",
            "  [227 227 227]\n",
            "  [227 227 227]]\n",
            "\n",
            " [[234 227 227]\n",
            "  [228 228 228]\n",
            "  [228 228 228]\n",
            "  ...\n",
            "  [227 227 227]\n",
            "  [227 227 227]\n",
            "  [227 226 218]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADHElEQVR4nO3ZsW3DMBBAUTLwGN7E83sT7XFp0sVR\nESD2d/BeSTYHQZ8EpD0zs4Ccj1cPADwmTogSJ0SJE6LECVGXs83b7fasOd7UXmv52H1m77X8Dzh3\nv98frrs5IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAl\nTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR\n4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQ\nJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChx8rfm1QO8r8vZ5nEcz5rjTc1a\na796iLSZtbZH9CtuTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQ\nJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJ\nUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqc\nECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFqz8z8tHkcxzNneUOz\n9na+nTl5vfhyvV4frl+ePMc/s718/BnHPkSJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKE\nKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVO\niBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHi\nhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBC1\nZ2ZePQTwnZsTosQJUeKEKHFClDghSpwQ9QmYPyRvL4hiJQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mroGw7Fl5OdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}