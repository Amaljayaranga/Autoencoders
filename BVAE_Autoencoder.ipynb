{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BVAEwithDensenet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNL+72NpLT4JeSg2OBLwR53",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amaljayaranga/Autoencoders/blob/master/BVAE_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PwEqz1p7KTh",
        "colab_type": "code",
        "outputId": "d181b0b2-3af7-4137-9df3-8bea7366e5eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from argparse import ArgumentParser\n",
        "import seaborn as sns;sns.set()\n",
        "\n",
        "parser = ArgumentParser(description='BetaVAE Model')\n",
        "parser.add_argument('--batch_size', type=int, default=16)\n",
        "parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
        "parser.add_argument('--num_epochs', type=int, default=2)\n",
        "parser.add_argument('--validation_split', type=float, default=0.2)\n",
        "parser.add_argument('--beta', type=float, default=10.0)\n",
        "parser.add_argument('--weight_decay', type=float, default=1e-5)\n",
        "parser.add_argument('--z_features', type=int, default=64)\n",
        "parser.add_argument('--mode', type=str, default='eval')\n",
        "parser.add_argument('--device', type=str, default='cuda')\n",
        "\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "DEVICE = args.device\n",
        "if not torch.cuda.is_available():\n",
        "    DEVICE = 'cpu'\n",
        "\n",
        "train_dataset = MNIST('./data', transform=transforms.ToTensor(), train=True, download=True)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "split = int(np.floor(args.validation_split * len(train_dataset)))\n",
        "indices = list(range(len(train_dataset)))\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "dataloaders = []\n",
        "mnist_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size,\n",
        "                                                 sampler=train_sampler)\n",
        "mnist_val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size,\n",
        "                                               sampler=valid_sampler)\n",
        "\n",
        "dataloaders.append(mnist_train_loader)\n",
        "dataloaders.append(mnist_val_loader)\n",
        "\n",
        "test_dataset = MNIST('./data', transform=transforms.ToTensor(), train=False, download=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "        )\n",
        "        self.encoder.add_module('reshape', Flatten())\n",
        "        self.fcmu = nn.Linear(in_features= args.z_features, out_features=16)\n",
        "        self.fcvar = nn.Linear(in_features = args.z_features, out_features=16)\n",
        "        self.fcd = nn.Linear(in_features=16, out_features=16)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=4, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(in_channels=8, out_channels=4, kernel_size=4, stride=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(in_channels=4, out_channels=1, kernel_size=4, stride=2),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return self.fcmu(x), self.fcvar(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = self.decoder(z)\n",
        "        return torch.sigmoid(z)\n",
        "\n",
        "    def reparametrize(self, mu, var):\n",
        "        std = torch.exp(0.5 * var)\n",
        "        eps = torch.rand_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, var = self.encode(x)\n",
        "        z = self.reparametrize(mu, var)\n",
        "        z = self.fcd(z)\n",
        "        z = z.view(-1, 16, 1, 1)\n",
        "        return self.decode(z), mu, var\n",
        "\n",
        "\n",
        "model = Model()\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "if args.mode == 'train':\n",
        "\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
        "    print('training started')\n",
        "    minimum_loss = float('Inf')\n",
        "\n",
        "    training_losses = []\n",
        "    rec_losses = []\n",
        "    KL_losses = []\n",
        "    validation_losses = []\n",
        "    epochs = []\n",
        "\n",
        "    for epoch in range(1, args.num_epochs + 1):\n",
        "        epochs.append(epoch)\n",
        "\n",
        "        for dataloader_idx, dataloader in enumerate(dataloaders):\n",
        "            stage = ''\n",
        "\n",
        "            if dataloader == mnist_train_loader:\n",
        "                model.train()\n",
        "                torch.set_grad_enabled(True)\n",
        "            else:\n",
        "                model.eval()\n",
        "                torch.set_grad_enabled(False)\n",
        "\n",
        "            epoch_loss = []\n",
        "            epoch_rec_loss = []\n",
        "            epoch_KL_loss = []\n",
        "\n",
        "            for batch in dataloader:\n",
        "                images, labels = batch\n",
        "                images = images.to(DEVICE)\n",
        "\n",
        "                images = images.view(images.size(0), 1, 28, 28)\n",
        "                y, mu, var = model.forward(images)\n",
        "\n",
        "                recons_loss = F.mse_loss(y, images)\n",
        "                KLD = -0.5 * torch.sum(1 + torch.log(var.pow(2)) - mu.pow(2) - var.pow(2))\n",
        "                loss = recons_loss + args.beta * KLD\n",
        "\n",
        "                epoch_loss.append(loss.to('cpu').item())\n",
        "                epoch_rec_loss.append(recons_loss.to('cpu').item())\n",
        "                epoch_KL_loss.append(KLD.to('cpu').item())\n",
        "\n",
        "                if dataloader == mnist_train_loader:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            if dataloader == mnist_train_loader:\n",
        "                training_losses.append(np.mean(epoch_loss))\n",
        "                rec_losses.append(np.mean(epoch_rec_loss))\n",
        "                KL_losses.append(np.mean(epoch_KL_loss))\n",
        "                stage = 'train'\n",
        "            else:\n",
        "                validation_losses.append(np.mean(epoch_loss))\n",
        "                stage = 'eval'\n",
        "\n",
        "            if dataloader == mnist_train_loader:\n",
        "                print(\n",
        "                    f'epoch: {epoch} stage: {stage} loss: {np.mean(epoch_loss)} rec: {np.mean(epoch_rec_loss)} KL: {np.mean(epoch_KL_loss)}')\n",
        "            else:\n",
        "                print(f'epoch: {epoch} stage: {stage} loss: {np.mean(epoch_loss)}')\n",
        "\n",
        "            if dataloader_idx == 1:\n",
        "                if minimum_loss > np.mean(validation_losses):\n",
        "                    minimum_loss = np.mean(validation_losses)\n",
        "                    torch.save(model, 'vae_best.pt')\n",
        "                    model = model.to('cuda')\n",
        "                    print('Model is saving')\n",
        "\n",
        "    plt.plot(epochs, training_losses, label=\"train\")\n",
        "    plt.plot(epochs, validation_losses, label=\"eval\")\n",
        "    plt.plot(epochs, rec_losses, label=\"REC\")\n",
        "    plt.plot(epochs, KL_losses, label=\"KL\")\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title('training , validation loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "if args.mode == 'eval':\n",
        "    model = torch.load('vae_best.pt')\n",
        "    model = model.to(DEVICE)\n",
        "    model.eval()\n",
        "    torch.set_grad_enabled(False)\n",
        "\n",
        "\n",
        "    def splot(img1, img2):\n",
        "        f, axarr = plt.subplots(1, 2)\n",
        "        axarr[0].imshow(transforms.ToPILImage()(img1))\n",
        "        axarr[1].imshow(transforms.ToPILImage()(img2))\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_image1 = next(iter(test_dataloader))[0][6]\n",
        "\n",
        "\n",
        "        test_image = test_image1.view(1, 1, 28, 28)\n",
        "        test_image = test_image.to(DEVICE)\n",
        "        model_img, mu, var = model(test_image)\n",
        "\n",
        "        model_img = model_img.cpu().squeeze(0)\n",
        "\n",
        "        splot(test_image1, model_img)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}